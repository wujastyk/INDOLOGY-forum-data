Initial capital
At 12:44 1996-04-12 BST, Mikael Aktor wrote:
I would like to abuse this occasion to argue in favour of two-character
diacritical encodings, in particular to  bluntly propagate (once more) a
quite wide-spread Japanese convention, allegedly invented in Tookyoo, by
people who worked on main-frame computers who couldn't handle capitals (so
Harvard-Kyooto was not an option). This convention, which uses "@" as a
second character after the diacritic's root-letter (i.e. "a@" for "long a",
some exceptions for .n etc.), is admittedly more difficult to read than
Harvard, at least in some cases, but it has one big advantage: If you have
data which contains English, too, and if you want to use it on your own
computer with a word-processor of your choice and a diacritical font of your
choice, it is much easier and inambiguous to write a macro for conversion.
The same routine is not possible for both Harvard-Kyooto and Velthuis,
because characters which are used in non-Sanskrit are also used in marking
diacritics. 
By the same token, the "@"-convention is also very useful for tormented
Windows-users like myself, who switch between diacritical fonts ("the
eternal quest for aesthetically pleasing Sanskrit diacritics - yet another
never-ending story"). Given that all these fonts have different positions
for their diacritics (amongst which I would also count non-English letters
such as German umlaut etc.), a fact which makes me increasingly angry,
replacing one character by another with a simple macro won't do. If you
have, for example, the long a on ANSI 0140 and change to a font which has it
on ANSI 0167, and if you want to change the long i from your old font on
ANSI 0167 to ANSI 0189, you end up with a terrible mess. So you need a
"go-between"-ASCII-convention, and for papers in English/German/Swahili or
whatever which contain Sanskrit/Tibetan passages, you do need a
two-character encoding. 
Birgit Kellner
Department for Indian Philosophy
University of Hiroshima
